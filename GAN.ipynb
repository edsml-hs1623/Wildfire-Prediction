{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PymTwMRujKY"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAKW7EtZujKa",
        "outputId": "f2789c9a-df62-4a86-a33d-5d22579adbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.3.4)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.25.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (24.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2.0.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2024.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install livelossplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I-b20UC6ujKb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datetime, time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7fWU7PhuxVU",
        "outputId": "3c02801e-677b-43bb-d757-955a030df591"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCbdI3cTujKc",
        "outputId": "d1e2caa7-d7a0-4e97-8c8f-0d9136c2b37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before reshaping: (12500, 256, 256)\n",
            "After reshaping: (12500, 65536)\n"
          ]
        }
      ],
      "source": [
        "# load the training data and reshape\n",
        "train = np.load('/content/gdrive/MyDrive/Data/Ferguson_fire_train.npy')\n",
        "\n",
        "print(f\"Before reshaping: {np.shape(train)}\")\n",
        "\n",
        "train_1D = np.reshape(\n",
        "    train, (np.shape(train)[0], np.shape(train)[1] * np.shape(train)[2])\n",
        ")\n",
        "print(f\"After reshaping: {train_1D.shape}\")\n",
        "\n",
        "train = np.array(train)\n",
        "train_1D = np.array(train_1D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxhT77NBujKd",
        "outputId": "a0d3e149-2f0b-406f-f016-54d8eed222d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before reshaping: (5000, 256, 256)\n",
            "After reshaping: (5000, 65536)\n"
          ]
        }
      ],
      "source": [
        "# load the test data and reshape\n",
        "test = np.load('/content/gdrive/MyDrive/Data/Ferguson_fire_test.npy')\n",
        "\n",
        "print(f\"Before reshaping: {np.shape(test)}\")\n",
        "\n",
        "test_1D = np.reshape(\n",
        "    test, (np.shape(test)[0], np.shape(test)[1] * np.shape(test)[2])\n",
        ")\n",
        "print(f\"After reshaping: {test_1D.shape}\")\n",
        "\n",
        "test = np.array(test)\n",
        "test_1D = np.array(test_1D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7hobVlbujKd",
        "outputId": "fbeb8dc4-7e2b-4c70-9c5e-225cb2101024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available!\n"
          ]
        }
      ],
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim=100, g_output_dim=256*256):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim=256*256):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))\n",
        "\n",
        "# build model\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# define loss\n",
        "criterion = nn.BCELoss()\n",
        "z_dim = 100\n",
        "\n",
        "# optimiser\n",
        "lr = 0.0001\n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "zHKWdJnnYHq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def D_train(x):\n",
        "    D.train()\n",
        "    D_optimizer.zero_grad()\n",
        "\n",
        "    # train discriminator on real data -- assign high score (use 1 here)\n",
        "    x_real, y_real = x.view(-1, 256*256), torch.ones(batch_size, 1)  # we are assigning the label 'real data' to the samples (don't care anymore about what number they are)\n",
        "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "\n",
        "    # train discriminator on fake data -- assign low score (use 0 here)\n",
        "    # sample vector and produce generator output\n",
        "    z = torch.randn(batch_size, z_dim).to(device)\n",
        "    x_fake, y_fake = G(z), torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "\n",
        "    # combine the losses\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "\n",
        "    # model update\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return  D_loss.data.item()  ### deprecated version of loss.detach(), basically gets access to the tensor without the computational graph attached\n"
      ],
      "metadata": {
        "id": "-5qzpBx8YSJZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader\n",
        "\n",
        "# Convert your training data to PyTorch tensors\n",
        "train_data = torch.tensor(train_1D, dtype=torch.float32)\n",
        "test_data = torch.tensor(test_1D, dtype=torch.float32)\n",
        "\n",
        "# Create a TensorDataset from your training data\n",
        "\n",
        "# transform = transforms.Compose([transforms.ToTensor(),\n",
        "#                                 transforms.Normalize(mean=(0.5), std=(0.5))])\n",
        "\n",
        "train_dataset = TensorDataset(train_data)\n",
        "test_dataset = TensorDataset(test_data)\n",
        "\n",
        "# Specify batch size\n",
        "batch_size = 100\n",
        "\n",
        "# Create a DataLoader for your training dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "aQHJfEzuYLsq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def G_train(x):\n",
        "    G.train()\n",
        "    G_optimizer.zero_grad()\n",
        "\n",
        "    # sample vector and produce generator output\n",
        "    z = torch.randn(batch_size, z_dim).to(device)\n",
        "    G_output = G(z)\n",
        "\n",
        "    # obtain scores from D for the generated data\n",
        "    D_output = D(G_output)\n",
        "\n",
        "    # train generator to \"fool\" discriminator\n",
        "    y = torch.ones(batch_size, 1).to(device)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # model update\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    return G_loss.data.item()  ### deprecated version of loss.detach(), basically gets access to the tensor without the computational graph attached\n"
      ],
      "metadata": {
        "id": "ZdgBdwI0YTz7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 100\n",
        "groups = {'Loss': ['D_Loss', 'G_Loss']}\n",
        "liveloss = PlotLosses(groups=groups)\n",
        "\n",
        "for epoch in range(1, n_epoch + 1):\n",
        "    D_losses, G_losses = [], []\n",
        "    logs = {}\n",
        "\n",
        "    for batch_idx, (real_images,) in enumerate(train_loader):\n",
        "        real_images = real_images.view(-1, 256*256).to(device)\n",
        "\n",
        "        D_loss = D_train(real_images)\n",
        "        G_loss = G_train(real_images.size(0))\n",
        "\n",
        "        D_losses.append(D_loss)\n",
        "        G_losses.append(G_loss)\n",
        "\n",
        "    logs['D_Loss'] = torch.tensor(D_losses).mean().item()\n",
        "    logs['G_Loss'] = torch.tensor(G_losses).mean().item()\n",
        "\n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()\n",
        "\n",
        "    # save after training\n",
        "    if(np.mod(epoch, 100) == 0):\n",
        "      torch.save(G.state_dict(), \"./GAN/Generator_{:03d}.pth\".format(epoch))"
      ],
      "metadata": {
        "id": "gff86nqQYZ98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.load_state_dict(torch.load(\"./GAN/Generator_{:03d}.pth\".format(epoch)))\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_z = torch.randn(batch_size, z_dim).to(device)\n",
        "    generated = G(test_z)\n",
        "\n",
        "    # save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')\n",
        "fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n",
        "for ax, img in zip(axarr.flatten(), generated.view(generated.size(0), 256, 256).cpu()):\n",
        "  ax.imshow(img, cmap=\"gray\")\n",
        "plt.title('Epoch = {:03d}'.format(epoch))"
      ],
      "metadata": {
        "id": "AhU4eRR1YwqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing DCGAN"
      ],
      "metadata": {
        "id": "1mjnyBHsX35x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jouD4AnCujKe"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim=100, g_output_dim=256):\n",
        "        super().__init__()\n",
        "        self.init_size = g_output_dim // 8\n",
        "        self.fc1 = nn.Linear(g_input_dim, 128 * self.init_size ** 2)\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(16, 1, 3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"Generator input shape:\", x.shape)\n",
        "        x = self.fc1(x)\n",
        "        print(\"After fc1 shape:\", x.shape)\n",
        "        x = x.view(x.shape[0], 128, self.init_size, self.init_size)\n",
        "        print(\"After view shape:\", x.shape)\n",
        "        x = self.conv_blocks(x)\n",
        "        print(\"After conv_blocks shape:\", x.shape)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim=256):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout2d(0.25),\n",
        "            nn.Conv2d(16, 32, 3, 2, 1),\n",
        "            # nn.ZeroPad2d((0, 1, 0, 1)),  # the fucking mismatch is from here\n",
        "            nn.BatchNorm2d(32, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout2d(0.25),\n",
        "            nn.Conv2d(32, 64, 3, 2, 1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout2d(0.25),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout2d(0.25)\n",
        "        )\n",
        "        # Calculate the expected input size for the linear layer\n",
        "        ds_size = d_input_dim // 8\n",
        "        self.linear_input_size = 128 * ds_size ** 2\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(self.linear_input_size, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"Discriminator input shape:\", x.shape)\n",
        "        x = self.model(x)\n",
        "        print(\"After model shape:\", x.shape)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        print(\"After flatten shape:\", x.shape)\n",
        "        x = self.adv_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# define loss\n",
        "criterion = nn.BCELoss()\n",
        "z_dim = 100\n",
        "\n",
        "# optimiser\n",
        "lr = 0.0001\n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "2f_5bmrLCWsv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NumpyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.data = np.load(data_path).astype(np.float32)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        image = torch.from_numpy(image)\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "        return image"
      ],
      "metadata": {
        "id": "4yNBufk0L4Me"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zxwC490mujKf"
      },
      "outputs": [],
      "source": [
        "# DataLoader\n",
        "\n",
        "# Convert your training data to PyTorch tensors\n",
        "# train_data = torch.tensor(train, dtype=torch.float32)\n",
        "# test_data = torch.tensor(test, dtype=torch.float32)\n",
        "\n",
        "# Create a TensorDataset from your training data\n",
        "\n",
        "transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                transforms.Resize(256),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5), std=(0.5))])\n",
        "\n",
        "train_data = NumpyDataset('/content/gdrive/MyDrive/Data/Ferguson_fire_train.npy', transform=transform)\n",
        "test_data = NumpyDataset('/content/gdrive/MyDrive/Data/Ferguson_fire_test.npy', transform=transform)\n",
        "\n",
        "# Specify batch size\n",
        "#with depreceated functionality in torch, this needs to be an even divisible of\n",
        "#the total input size\n",
        "batch_size = 100\n",
        "\n",
        "# Create a DataLoader for your training dataset\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Rv2ZrQSOujKg"
      },
      "outputs": [],
      "source": [
        "def D_train(x):\n",
        "    D.train()\n",
        "    D_optimizer.zero_grad()\n",
        "\n",
        "    # train discriminator on real data -- assign high score (use 1 here)\n",
        "    x_real, y_real = x.view(-1, 1, 256, 256), torch.ones(batch_size, 1)  # we are assigning the label 'real data' to the samples (don't care anymore about what number they are)\n",
        "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "\n",
        "    # train discriminator on fake data -- assign low score (use 0 here)\n",
        "    # sample vector and produce generator output\n",
        "    z = torch.randn(batch_size, z_dim).to(device)\n",
        "    x_fake, y_fake = G(z), torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "\n",
        "    # combine the losses\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "\n",
        "    # model update\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return  D_loss.data.item()  ### deprecated version of loss.detach(), basically gets access to the tensor without the computational graph attached\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VP6RL-QlujKg"
      },
      "outputs": [],
      "source": [
        "def G_train(x):\n",
        "    G.train()\n",
        "    G_optimizer.zero_grad()\n",
        "\n",
        "    # sample vector and produce generator output\n",
        "    z = torch.randn(batch_size, z_dim).to(device)\n",
        "    G_output = G(z)\n",
        "\n",
        "    # obtain scores from D for the generated data\n",
        "    D_output = D(G_output)\n",
        "\n",
        "    # train generator to \"fool\" discriminator\n",
        "    y = torch.ones(batch_size, 1).to(device)\n",
        "    # G_loss = criterion(D_output, y)\n",
        "    G_loss = criterion(D_output, torch.ones_like(D_output))\n",
        "\n",
        "    # model update\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    return G_loss.data.item()  ### deprecated version of loss.detach(), basically gets access to the tensor without the computational graph attached\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "vOm5b6YtujKh",
        "outputId": "f1d5d39b-7ee2-43b4-a399-a82a5e6d3c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator input shape: torch.Size([100, 1, 256, 256])\n",
            "After model shape: torch.Size([100, 128, 32, 32])\n",
            "After flatten shape: torch.Size([100, 131072])\n",
            "Generator input shape: torch.Size([100, 100])\n",
            "After fc1 shape: torch.Size([100, 131072])\n",
            "After view shape: torch.Size([100, 128, 32, 32])\n",
            "After conv_blocks shape: torch.Size([100, 1, 128, 128])\n",
            "Discriminator input shape: torch.Size([100, 1, 128, 128])\n",
            "After model shape: torch.Size([100, 128, 16, 16])\n",
            "After flatten shape: torch.Size([100, 32768])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (100x32768 and 131072x1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2f9362c74ff3>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mreal_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mD_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# G_loss = G_train(batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-6d1800f06294>\u001b[0m in \u001b[0;36mD_train\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mD_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mD_fake_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-a74009034780>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Flatten the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After flatten shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x32768 and 131072x1)"
          ]
        }
      ],
      "source": [
        "n_epoch = 20\n",
        "groups = {'Loss': ['D_Loss', 'G_Loss']}\n",
        "liveloss = PlotLosses(groups=groups)\n",
        "\n",
        "for epoch in range(1, n_epoch + 1):\n",
        "    D_losses, G_losses = [], []\n",
        "    logs = {}\n",
        "\n",
        "    for batch_idx, real_images in enumerate(train_loader):\n",
        "        real_images = real_images.view(-1, 256, 256).to(device)\n",
        "\n",
        "        D_loss = D_train(real_images)\n",
        "        # G_loss = G_train(batch_size)\n",
        "        G_loss = G_train(real_images.size(0))\n",
        "\n",
        "        D_losses.append(D_loss)\n",
        "        G_losses.append(G_loss)\n",
        "\n",
        "    logs['D_Loss'] = torch.tensor(D_losses).mean().item()\n",
        "    logs['G_Loss'] = torch.tensor(G_losses).mean().item()\n",
        "\n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()\n",
        "\n",
        "    # save every 20th epochs\n",
        "    if(np.mod(epoch, 20) == 0):\n",
        "      torch.save(G.state_dict(), \"./exp/Generator_{:03d}.pth\".format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qBtK9nmujKi"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    test_z = torch.randn(batch_size, z_dim).to(device)\n",
        "    generated = G(test_z)\n",
        "\n",
        "    # save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')\n",
        "fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n",
        "for ax, img in zip(axarr.flatten(), generated.view(generated.size(0), 28, 28).cpu()):\n",
        "  ax.imshow(img, cmap=\"gray\")\n",
        "plt.title('Epoch = {:03d}'.format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HDoTx5llUoLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}